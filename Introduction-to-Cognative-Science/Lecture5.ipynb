{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non Symbolic AI approach = Connectionism (Connection of Perceptrons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delta rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It aims to minimize the error between the predicted output and the actual target output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks are algorithmic in a limited sense\n",
    "- units/neurons have algorithms for updating activation levels\n",
    "- learning rules are algorithmic\n",
    "\n",
    "But not algorithmic in the same way as PSS\n",
    "- algorithms are not task-specific\n",
    "- algorithms do not operate over explicit representations(instead, they change weights and thresholds of individual unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use the symbol $\\Delta$ (big delta) to indicate the adjustment that we will make after each application of the rule, then the perceptron convergence rule can be written like this (remembering that $T$ is the threshold and $W_i$ is the $i$ th input):\n",
    "\n",
    "$\\Delta T = \\eta \\cdot \\delta$\n",
    "\n",
    "$\\Delta W_i = \\eta \\cdot \\delta \\cdot I_i$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checklist\n",
    "\n",
    "## Neurally Inspired Information Processing\n",
    "\n",
    "1. A fundamental question in thinking about how the brain processes information is how the activities of large populations of neurons give rise to complex sensory and cognitive abilities.\n",
    "   - Understanding how large groups of neurons collectively enable perception and cognition is a central issue in neuroscience.\n",
    "2. Existing techniques for directly studying the brain do not allow us to study what happens inside populations of neurons.\n",
    "   - Current brain imaging methods, like fMRI and PET, do not provide insights into the workings of neuron populations.\n",
    "3. Computational neuroscientists use mathematical models (neural networks) to study populations of neurons.\n",
    "   - Researchers use neural network models to indirectly study and understand neuron population behavior.\n",
    "4. These neural networks are made up of units loosely based on biological neurons. Each unit is connected to other units so that activation levels can be transmitted between them as a function of the strength of the connection.\n",
    "   - Neural network units mimic biological neurons and communicate based on connection strength, simulating brain function.\n",
    "\n",
    "## Single-Layer Networks\n",
    "\n",
    "1. We can use single-layer networks to compute some Boolean functions, in particular AND, OR, and NOT.\n",
    "   - Single-layer networks can perform basic logical operations like AND, OR, and NOT.\n",
    "2. Any digital computer can be simulated by a network of single-layer networks appropriately chained together.\n",
    "   - Chained single-layer networks can emulate the functioning of digital computers.\n",
    "3. Single-layer networks can learn by adjusting their weights to minimize their degree of error (the δ signal) according to the perceptron convergence rule.\n",
    "   - These networks learn by modifying weights to reduce error, following the perceptron convergence rule.\n",
    "4. Single-layer networks can only learn to compute functions that are linearly separable.\n",
    "   - They are limited to learning linearly separable functions, unable to solve more complex problems.\n",
    "\n",
    "## Multilayer Networks\n",
    "\n",
    "1. Multilayer networks have hidden units that are neither input units nor output units.\n",
    "   - These networks include hidden units, which are crucial for learning complex functions.\n",
    "2. The presence of hidden units enables multilayer networks to learn to compute functions that cannot be learned by single-layer networks (including functions that are not linearly separable).\n",
    "   - Hidden units allow multilayer networks to solve problems that single-layer networks cannot, including non-linearly separable functions.\n",
    "3. The backpropagation learning algorithm for multilayer networks adjusts the weights of hidden units as a function of how “responsible” they are for the error at the output units.\n",
    "   - Backpropagation updates hidden unit weights based on their contribution to output error.\n",
    "\n",
    "## Biological Plausibility\n",
    "\n",
    "1. Neural network units are much more homogeneous than real neurons. And real neural networks are likely to be both much larger and less parallel than network models.\n",
    "   - Artificial neural network units are uniform, whereas real neurons are diverse and less parallel.\n",
    "2. The backpropagation algorithm is not very biologically plausible. There is no evidence that error is propagated backward in the brain. And nature rarely provides feedback as detailed as the algorithm requires.\n",
    "   - Backpropagation lacks biological realism, as the brain does not use such detailed feedback for learning.\n",
    "3. However, there are other learning algorithms. Competitive networks using Hebbian learning do not require explicit feedback, and there is evidence for local learning in the brain.\n",
    "   - More biologically plausible algorithms like Hebbian learning exist, which do not need explicit feedback.\n",
    "\n",
    "## Information Processing in Neural Networks\n",
    "\n",
    "1. Representation in neural networks is distributed across the units and weights, rather than being encoded in discrete symbol structures, as in the physical symbol system hypothesis.\n",
    "   - Neural networks store information across units and connections, unlike discrete symbols in traditional systems.\n",
    "2. There are no clear distinctions to be drawn within neural networks either between information storage and information processing or between rules and representations.\n",
    "   - In neural networks, information storage and processing, as well as rules and representations, are intertwined.\n",
    "3. Neural networks are capable of sophisticated forms of learning, which makes them particularly suitable for modeling how cognitive abilities are acquired and how they evolve.\n",
    "   - Neural networks' advanced learning capabilities make them ideal for simulating cognitive development and evolution.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

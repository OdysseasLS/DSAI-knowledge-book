{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language and micro-worlds\n",
    "\n",
    "Language made humans to be able to think and build society."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ELIZA:** NLP model pcan make delusional thinking as a mind trick. Trying rephrazing user input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **PARRY**: simulated a patient with paranoid schizophrenia\n",
    "\n",
    "- **SHRDLU**: Model that try to undrestand language. 3 Actions:\n",
    "    1. The job of syntactic analysis: Decode the grammatical structure\n",
    "    2. The job of semantic analysis: assign meanings to the individual words (Syntax to semantics)\n",
    "    3.  Allign given information with previous information: To be able to give related response\n",
    "\n",
    "    - Understanding language as the interaction of separate cognitive processes, e.g. an algorithm for parsing noun phrases and an algorithm for parsing verb phrases.\n",
    "    - These algorithms process input according to rules, similar to a function in computer science.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual imagery\n",
    "\n",
    "Thought is impossible without an image. \n",
    "\n",
    "Blind people can use echolocation (locating by means of sound waves reflected back to the emitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize by imagination is not spatial representation\n",
    "\n",
    "Visual imagery allows us to mentally visualize things, resembling the real experience.\n",
    "\n",
    "Evidence suggests spatial correspondence between perception and imagery.\n",
    "\n",
    "Imagery can be spatial (like visualizing your room) or propositional (like describing where objects are located).\n",
    "\n",
    "Detail recognition in imagery mimics that of perception, suggesting a spatial mechanism at work.\n",
    "\n",
    "Physical properties such as brightness, contrast, and motion speed affect both perceived and imagined stimuli similarly, supporting spatial imagery over propositional representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marr’s levels of (top-down) analysis\n",
    "\n",
    "- Computational level\n",
    "    - Computation goal and appropriate strategy.\n",
    "- Representation and Algorithmic level\n",
    "    - Computational methode of that strategy.\n",
    "- Hardware Implementation level\n",
    "    - How is the system physically realized\n",
    "\n",
    "Top-Down analysis means from Total to detailed analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object recognition steps\n",
    "Image projected on retina \n",
    "\n",
    "$\\to$ perceptual constancy (The brain adjusts for changes in size, shape, and color due to different viewing angles) \n",
    "\n",
    "$\\to$ invariant representation of object ( The brain creates a stable and unchanging representation of the object in mind.)\n",
    "\n",
    "$\\to$ classification of object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification mechanisms\n",
    "\n",
    "Concepts are multimodal:\n",
    "- semantic\n",
    "- visual\n",
    "- auditory\n",
    "- tactile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Categorization by definition\n",
    "-  Categorization by prototypest\n",
    "-  Categorization by exemplarsg\n",
    "-  Biederman’s recognition-by-components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Checklist\n",
    "\n",
    "### Winograd’s SHRDLU\n",
    "\n",
    "1. **SHRDLU vs. Chatbots**:\n",
    "   - SHRDLU is more advanced than chatbots like ELIZA because it uses language not just to simulate conversation but to interact with and report on a virtual environment and plan actions within that environment.\n",
    "\n",
    "2. **Integration of Grammatical Rules**:\n",
    "   - It demonstrated how abstract grammatical rules could be represented in a cognitive system and integrated with environmental information, showcasing practical applications of theoretical linguistics.\n",
    "\n",
    "3. **Component Analysis**:\n",
    "   - The design of SHRDLU exemplifies the cognitive science approach of breaking down complex systems into distinct, specialized components, each performing specific information-processing tasks.\n",
    "\n",
    "4. **Algorithmic Implementation**:\n",
    "   - SHRDLU’s tasks are carried out algorithmically, as shown by Winograd’s use of flowcharts to detail the procedures for each component.\n",
    "\n",
    "### The Imagery Debate\n",
    "\n",
    "1. **Understanding Information Processing**:\n",
    "   - The experiments sparked deeper reflection among cognitive scientists on how information and its processing are understood.\n",
    "\n",
    "2. **Information Processing, Not Experience**:\n",
    "   - The debate focuses on the underlying information processing of mental imagery, not on the conscious experiences themselves.\n",
    "\n",
    "3. **Geometric Representations**:\n",
    "   - Experiments like mental rotation and scanning suggested that some cognitive tasks involve operations on geometrically encoded representations.\n",
    "\n",
    "4. **Digital vs. Imagistic Models**:\n",
    "   - The core of the debate is whether the effects observed in mental imagery experiments can be explained using digital information-processing models or if they require imagistic representations.\n",
    "\n",
    "### Marr’s Theory of Vision\n",
    "\n",
    "1. **Three Levels of Analysis**:\n",
    "   - Marr proposed three levels for analyzing cognitive systems: computational, algorithmic, and implementational.\n",
    "\n",
    "2. **Top-Down Analysis**:\n",
    "   - His analysis of vision exemplifies top-down analysis, starting with a broad characterization of the information-processing task at the computational level.\n",
    "\n",
    "3. **Algorithmic Details**:\n",
    "   - The computational analysis is detailed at the algorithmic level, where Marr explains how the task can be performed algorithmically.\n",
    "\n",
    "4. **Neurobiological Implementation**:\n",
    "   - The implementational level addresses how these algorithms are realized physically, incorporating neurobiological considerations into the analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

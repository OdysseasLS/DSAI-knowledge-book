## Dynamical Systems
## Checklist
##### Some cognitive scientists have turned to dynamical systems theory as an alternative to traditional information-processing models of cognition.

(1) A dynamical system is any system that evolves over time in a law-governed way, but what distinguishes the dynamical systems approach in cognitive science is the idea of studying cognitive systems with the tools of dynamical systems theory.

(2) Dynamical models use calculus-based methods to track the evolving relationship between a small number of variables over time – a trajectory through state space.

(3) Dynamical systems often display coupling (interdependencies between variables) and an attractor dynamics (there are points in the system’s state space on which many different trajectories converge).

(4) Cognitive systems modeled using dynamical systems theory do not display many of the classic features of information-processing systems. Dynamical models typically are not representational, computational, sequential, or homuncular.

##### Dynamical systems theory permits time-sensitive models of learning and skill acquisition in children.

(1) Case studies include learning to walk in infancy, as well as performance on the A-not-B search task.

(2) Support for the dynamical systems approach comes from experiments showing that performance can be drastically altered by manipulating factors that would typically be ignored by computational models.

(3) The explanatory power of the dynamical systems approach does not mean that it should replace information-processing approaches to cognitive science.

(4) The dynamical systems approach sheds light on cognitive systems at a particular level of organization. There is no reason to think that the level of explanation it provides should be the only one in cognitive science.

# Modularityof Mind & MentalArchitectures

Cognitive agents are standardly modeled in terms of quasi-autonomous information-processing systems, which raises the question of how those systems should be understood.
# Intelligent Agents

- Reflex Agents
    - **Production rules**: Operate using IF... THEN rules.
    - **Behavior**: Not cognitive; no information processing.
    - **Action**: Simply acts on given information without deeper reasoning.
    - **Example**: An agent that moves towards food when it detects it.

- Goal-based Agents
    - **Action**: Evaluates the consequences of possible actions based on goals.
    - **Decision-making**: Considers various actions and their outcomes before acting.
    - **Limitation**: Does not have the capacity to learn from past experiences.
    - **Example**: An agent that plans its path to find food.

- Learning Agents
    - **Error Detection**: Can identify and learn from mistakes.
    - **Adaptability**: Experiments with different strategies to achieve goals based on past performance.
    - **Example**: An agent that adjusts its approach to finding food if previous methods failed.
### 
The Massive Modularity Hypothesis
Darwinian Modules:

- Propose the mind consists entirely of modules evolved to solve specific adaptive problems.
- **Cheater Detection Module**: Enhanced reasoning with social conditionals (e.g., detecting rule violations).
### Hybrid Architectures: The Example of ACT-R
**ACT-R Architecture:**

ACT-R is a modular system that combines the symbolic approach associated with the physical symbol system hypothesis and the subsymbolic neural networks approach.

- Combines symbolic and subsymbolic information processing.
- Modules: Perceptual (input), Motor (output), Procedural Memory, Declarative Memory.
- Communication between modules occurs via buffers.
- Uses production rules and chunk-based knowledge representation.

- **Symbolic**: Explicit, rule-based processing of information in buffers.
- **Subsymbolic**: Underlying numerical evaluation that decides what information goes into buffers.
### Checklist
#### Computer scientists building intelligent agents distinguish different types of agent architectures.

(1) Simple reflex agents have condition-action rules (production rules) that directly link sensory and effector systems.

(2) Simple reflex agents are not cognitive systems, unlike goal-based agents and learning agents.

(3) Goal-based agents and learning agents are built up from subsystems that perform specific information-processing tasks.

#### Fodor’s Modularity Thesis

(1) The thesis is built on a rejection of horizontal faculty psychology (the idea that the mind is organized in terms of faculties such as memory and attention that can process any type of information).

(2) It proposes the existence of specialized information-processing modules that are:
- Domain-specific
- Informationally encapsulated (Modules work without being influenced by other information in the mind.)
- Mandatory (Modules operate automatically in response to stimuli.)
- Fast

(3) These modules may also have a fixed neural architecture and specific breakdown patterns.

(4) Modules are employed for certain basic types of information processing (e.g., shape analysis, color perception, and face recognition).

(5) Modules provide inputs to nonmodular, central processing – the realm of belief fixation and practical decision-making, among other things.

(6) Central processing is holistic, meaning it considers all available information and is not confined to specific types of data.

#### Massive Modularity Hypothesis

According to the massive modularity hypothesis, all information processing is modular. There is no domain-general information processing.

(1) The human mind is claimed to be a collection of specialized modules, each of which evolved to solve a specific set of problems encountered by our Pleistocene ancestors.

(2) Examples of these Darwinian modules are the cheater detection module and modules proposed for folk psychology (Helps understand others' thoughts and feelings (theory of mind)) and folk physics (Helps understand physical interactions and mechanics (intuitive mechanics)).

(3) According to the argument from error, domain-general cognitive mechanisms could not have evolved because there are no domain-general fitness criteria.

(4) According to the argument from statistics and learning, domain-general learning mechanisms cannot detect statistically recurrent domain-specific patterns (such as the kin selection equation proposed by W. D. Hamilton).

(5) Both of these arguments can be satisfied with the much weaker claim that there are innate, domain-specific bodies of knowledge.

#### Hybrid Architectures: The Example of ACT-R

ACT-R is an example of a hybrid architecture that combines both symbolic and subsymbolic elements.

(1) Knowledge in ACT-R is represented in two different ways 
- **declarative knowledge** is represented in chunks
- **procedural knowledg**e is represented through production rules.

(2) Items of knowledge become available for general information processing when they appear in one of the buffers (temporary storage areas used to hold and process pieces). This general information processing is fundamentally symbolic in character.

(3) In contrast, the processes that determine whether a particular item of knowledge ends up in a buffer are subsymbolic – equations, for example, that calculate how useful a given production rule might be in a particular context.

(4) These processes are subsymbolic because they do not exploit or depend upon the internal symbolic structure of the item of knowledge.
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Limitations of Statistical Tests:**\n",
    "   - **P-Value Misinterpretation:**\n",
    "     - $ p $-value measures $ P(\\text{data} | H_0) $, not $ P(H_0 | \\text{data}) $.\n",
    "     - Frequentist methods do not provide direct probabilities for hypotheses.\n",
    "   - **P-Hacking:**\n",
    "     - Manipulating data collection, analysis, or reporting to achieve $ p < 0.05 $.\n",
    "     - Includes stopping data collection early, selective reporting, or transforming data.\n",
    "   - **Publication Bias:**\n",
    "     - Favoring significant results leads to overrepresentation of Type I errors.\n",
    "   - **Practical vs. Statistical Significance:**\n",
    "     - Statistical significance does not guarantee meaningful results.\n",
    "\n",
    "**Causality:**\n",
    "   - Criteria for causality:\n",
    "     1. **Association:** Relationship between variables.\n",
    "     2. **Time Order:** Cause must precede effect.\n",
    "     3. **No Alternative Explanations:** Control for lurking variables.\n",
    "   - Spurious correlations can mislead causal interpretations.\n",
    "\n",
    "**Scientific Fraud:**\n",
    "   - Examples:\n",
    "     - **Diederik Stapel:** Fabricated data, 55 papers retracted.\n",
    "     - **Brian Wansink:** Retractions due to data manipulation and errors in 52+ papers.\n",
    "   - Common issues:\n",
    "     - \"Salami publishing\" (splitting one dataset into multiple papers).\n",
    "     - Post-hoc hypotheses and manipulated analyses.\n",
    "\n",
    "**Fake News in Research:**\n",
    "   - Cherry-picking significant results from multiple measurements inflates Type I errors.\n",
    "   - Example: Chocolate diet study with multiple outcome measures misleadingly highlighted a spurious significant result."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

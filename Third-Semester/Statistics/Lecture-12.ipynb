{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Fit:**\n",
    "   - **Underfitting:** Model too simple, high bias, low variance, poor data capture.\n",
    "   - **Overfitting:** Model too complex, low bias, high variance, fits noise, poor generalization.\n",
    "   - **Good Fit:** Balanced bias and variance, captures relationships without noise.\n",
    "\n",
    "**Model Selection:**\n",
    "   - **Comparing Models:**\n",
    "     - **Nested Models:** One model fully contains another (e.g., adding/removing predictors).\n",
    "     - **Unnested Models:** Models differ in variables used, not comparable with F-test.\n",
    "   - **F-Test:** For nested models, tests if additional parameters significantly improve fit.\n",
    "   - **Model Fit Indices:**\n",
    "     - Adjusted $ R^2 $: Penalizes for extra parameters, decreases if they don't improve the model.\n",
    "     - PRESS: Predicted sum of squared errors via cross-validation.\n",
    "     - AIC/BIC: Penalize model complexity, lower is better.\n",
    "     - MDL: Balances model simplicity and residual error.\n",
    "\n",
    "**Model Selection Strategies:**\n",
    "   - **Backward Elimination:** Start with all predictors, remove insignificant ones.\n",
    "   - **Forward Selection:** Start with no predictors, add significant ones iteratively.\n",
    "   - **Automated Methods (AutoML):** Software-based selection strategies.\n",
    "\n",
    "**Model Validation:**\n",
    "   - **Purpose:** Confirm the model generalizes well to new data.\n",
    "   - **Methods:**\n",
    "     - Split data into training and testing sets (e.g., 70/30 split).\n",
    "     - Cross-validation:\n",
    "       - **Leave-One-Out (LOOCV):** Each observation is left out once, slow but uses all data.\n",
    "       - **k-Fold:** Divide data into $ k $ parts, train on $ k-1 $ folds, test on the remaining.\n",
    "     - **Train/Validate/Test Split:**\n",
    "       - Separate test set for final evaluation.\n",
    "       - Use cross-validation on train + validate set to select the model.\n",
    "   - **Symptoms of Overfitting/Underfitting:**\n",
    "     - Overfitting: Low train error, high test error.\n",
    "     - Underfitting: High error on both train and test sets."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Core Components of a Robot**:\n",
    "   - **Hardware**:\n",
    "     - **Sensors**: Cameras (RGB, Depth), microphones, LiDAR (long-distance measurements), tactile sensors (Touch sensor).\n",
    "     - **Actuators**(For movement): Motors, pneumatic systems (used in RoboThespian), and speakers.\n",
    "\n",
    "   **LiDAR**(Light Detection and Ranging): \n",
    "\n",
    "   <img src=\"https://geospatialmedia.s3.amazonaws.com/wp-content/uploads/2019/01/Wired1.jpg\" height=\"200\">\n",
    "\n",
    "### 2. **Types of Robots**:\n",
    "   - **Humanoid**: Pepper, iCub, Robovie (human-like body and face features).\n",
    "   - **Androids**: Close human resemblance (Geminoid, Kokoro).\n",
    "   - **Zoomorphic**: Animal-like robots (Aibo, Paro).\n",
    "   - **Social drones**: Flying robots that interact with humans.\n",
    "   - **Projection robots**: Use projections to simulate a face (e.g., Furhat).\n",
    "   - **Virtual agents**: Not physical robots but AI-powered avatars.\n",
    "\n",
    "### 4. **Robot Control Systems**:\n",
    "   - **Sense-Plan-Act Model**: Robots sense their environment, plan their actions, and execute them.\n",
    "   - **Subsumption Architecture**: Simple behaviors are triggered quickly, used for immediate responses (e.g., emergency stop)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Middleware\n",
    "\n",
    "Application software can directly run on the operating system, robotic applications often are run through middleware, consisting of many small pieces of software modules. Middleware is considered a “software glue,” being in the middle of software modules and the operating system.\n",
    " Middleware handles differences in hardware, allowing sensors to be used interchangeably by standardizing data formats.\n",
    "\n",
    "The Robot Operating System (ROS) is a middleware platform, not an operating system. Rather, it is a collection of software modules and tools you can operate Nao and Pepper with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Motors**:\n",
    "\n",
    "1. **DC Servo Motor**: The standard actuator for robots, consisting of a DC motor, microcontroller, and a sensor (potentiometer or encoder) that provides the motor’s position.\n",
    "  \n",
    "2. **PWM Control**: Speed is controlled using Pulse-Width Modulation (PWM), where on/off pulses determine motor speed. Feedback control adjusts motor position by comparing actual position with the desired one.\n",
    "\n",
    "3. **Position and Velocity Control**: In robot arms and heads, the controller performs position control to move the motor to a specific angle. For mobile robots (e.g., wheels), velocity control is used to adjust speed.\n",
    "\n",
    "4. **Degrees of Freedom (DOF)**: The number of motors depends on the robot’s design and function. For instance, Roomba has 2 DOFs, a humanoid robot's head can have 3 DOFs (pan, tilt, yaw), and robot arms can have up to 7 DOFs for manipulation.\n",
    "\n",
    "Pointing finger has 4 degrees of freedom (DOFs).\n",
    "\n",
    "<img src=\"https://www.researchgate.net/publication/288021741/figure/fig1/AS:669004922376195@1536514611397/Bones-and-joints-of-the-human-hand-DIP-Distal-Interphalangeal-joint-PIP-Proximal.jpg\" height=\"300\">\n",
    "\n",
    "The minimum number of Degrees of Freedom (DOFs) that a robot arm needs to grasp an object from any direction is **6 DOFs**.\n",
    "\n",
    "- **3 DOFs** for positioning the end effector (the \"hand\" or \"gripper\") in 3D space (X, Y, and Z axes).\n",
    "- **3 DOFs** for orienting the end effector (to change its pitch, yaw, and roll) to grasp the object from any direction.\n",
    "\n",
    "5. **End Effectors**: Robot arms need grippers or hands to grasp objects. A simple gripper may have 1 DOF, while more complex hands have multiple DOFs for precise movements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Transfer Learning\n",
    "\n",
    "**Transfer Learning Definition**: Transfer learning, or fine-tuning, solves this by reusing part of an already trained neural network and adding a small labeled dataset to tune specific parts of the network, usually near the output layer.\n",
    "\n",
    "**Efficiency**: This allows the model to learn new skills or adapt to new tasks with a much smaller dataset compared to training a model from scratch like Language models like BERT and GPT, which are pre-trained on massive amounts of text, can be fine-tuned with much smaller data sets (e.g., less than 100 sentences) for specific tasks like intent recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "The technologies typically used as **sensors** on robots are **Camera**, **Microphone**, **LiDAR**and **Ultrasound sonar**.\n",
    "\n",
    "**Loudspeakers**, **LED lights**, and **Servo motors** are not sensors. Loudspeakers are output devices, LED lights provide illumination, and servo motors are actuators used for movement which is simple motors for cheap robots controlled by the duty cycle of the control signal and continuously changes direction to maintain its set position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "The inertial measurement unit allows Pepper to measure its bodily orientation, which is fundamental for balance and localization."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

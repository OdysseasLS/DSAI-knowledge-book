{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ELIZA** -> Chatbot with **pattern-matching rule**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Dialogue Systems**: Frame-Based like **Frame** (slot, slot, slot, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Research Process (8 Steps)**:\n",
    "   1. **Research Topic**\n",
    "   2. **Research Question/Hypothesis**\n",
    "   3. **Research Strategy and Experiment Design**:\n",
    "      - Types of research strategies:\n",
    "        - **Descriptive**: Describes current states of variables.\n",
    "        - **Correlational**: Examines relationships between variables.\n",
    "        - **Experimental**: Determines cause-effect relationships by manipulating variables.\n",
    "      - Experiment designs include:\n",
    "         - **within-subjects**: Same participants experience all conditions.\n",
    "         - **between-subjects**: Different participants for each condition.\n",
    "         - **factorial designs**: Tests multiple variables simultaneously.\n",
    "   4. **Operationalizing Variables**: Define variables in measurable terms, ensuring their reliability and validity.\n",
    "   5. **Selecting a Sample**\n",
    "   6. **Data Collection**\n",
    "   7. **Data Processing and Analysis**\n",
    "   8. **Reporting Results I**(ntroduction)**M**(ethods)**R**(esults)a**D**(iscussion) **format)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Study type in SIA Research**:\n",
    "   - **Interviews**\n",
    "   - **Perception-only Studies**: Focus on participants’ perceptions without interaction, often used in early stages of development.\n",
    "   - **Interaction Studies**: Evaluate users interaction with SIAs and measure behavior or outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Virtual Agent Construction**: 3D models, Texture mapping and Shading techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Nonverbal Behavior Representation**\n",
    "   - **Coding Schemes**: FACS (Facial Action Coding System) Breaking facial expressions into muscular movements (AUs or Action Units).\n",
    "   - **Body Coding Systems**: BACS (Body Action Coding System) focuses on body movements and emotions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Models and Approaches**:\n",
    "    - **Rule-based Models**: Use social science rules to create nonverbal behaviors.\n",
    "    - **Performance-based Models**: Rely on human recordings to animate gestures.\n",
    "    - **Machine Learning Models**\n",
    "\n",
    "**Challenges in Multimodal Behavior Modeling**:\n",
    "- Addressing **polysemy**, where a single gesture can have multiple meanings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Rule-based vs. Data-driven Approaches**\n",
    "   - **Rule-based models**: Use predefined rules and linguistic information to generate gestures.\n",
    "      - **Cerebella Architecture**:\n",
    "      - A hybrid system that uses both **acoustic** and **linguistic elements** to dynamically generate gestures with both the speech's auditory cues and its semantic structure.\n",
    "      - Used in both **virtual agent** and **social robotics**.\n",
    "      - Divides its process into stages:\n",
    "      1. Input treatment (text and audio processing).\n",
    "      2. Communicative functions (CFs) like emotion, emphasis analysis.\n",
    "      3. Behavior mapping based on the context.\n",
    "      4. Animation scheduling.\n",
    "\n",
    "      - **GRETA Architecture**:\n",
    "         - Uses **high-level concepts** and external context (e.g., **dialogue goals** or **user moves**) to influence gesture generation by **communicative intentions**\n",
    "      \n",
    "**Workflow**:\n",
    "   1. **User Input**\n",
    "   2. **MIND**: The system processes this input, deciding the agent’s emotional tone and what it should say.\n",
    "   3. **MIDAS**: Adds details to the agent’s response by selecting appropriate gestures and expressions that match the speech.\n",
    "   4. **BODY**: The chosen gestures are generated and timed perfectly with the speech for a natural response.\n",
    "   5. **User Model & Context Features**: Throughout, the system considers the user's preferences, reactions, and the external context to tailor the response, ensuring it fits the conversation setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Moravec’s Paradox**: Machines perform complex tasks, but simple tasks like those a child can do are extremely difficult for robots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Morphology** prioritizes a robot's practical design for specific tasks over appearance.\n",
    "- **Anthropomorphism** focuses on adding human-like features and behaviors to enhance social interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Design Patterns**: Reusable solutions to common problems in HRI design, such as communication patterns, can be applied across different robot designs.\n",
    "    - **Underpromise and Overdeliver**: Set realistic expectations to avoid disappointment; don’t overhype a robot’s abilities.\n",
    "    - **Interaction Expands Function**: `Open-ended` design allows users to adapt the robot to their own needs and expectations.\n",
    "    - **Do Not Mix Metaphors**: Keep design consistent—appearance and behavior should align to avoid discomfort or confusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Engineering Design Process**: Emphasizes technical problem-solving through simulations, but is limited in open-ended contexts.\n",
    "- **User-Centered Design (UCD)**: Involves users to ensure designs meet their needs, with early prototype testing.\n",
    "- **Participatory Design**: Collaborative approach where users co-create designs, essential for specific groups like the elderly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Measuring Anthropomorphization**:\n",
    "   - **Explicit measurements** involve directly asking people about their perceptions.\n",
    "      - **Mind perception**: assess people believe a robot has **agency** (the ability to act intentionally) and **experience** (the ability to feel emotions).\n",
    "      - **Warmth and competence - Robotic Social Attributes Scale (RoSAS)**: how friendly (warm) and capable (competent) they are.\n",
    "      - The **Godspeed Questionnaire**: evaluate human-robot interaction through five key dimensions:\n",
    "         - **Anthropomorphism** – How human-like the robot appears.\n",
    "         - **Animacy** – How \"alive\" or animated the robot seems.\n",
    "         - **Likeability**\n",
    "         - **Intelligence**\n",
    "         - **Safety** – How safe the person feels interacting with the robot.\n",
    "\n",
    "   - **Implicit measurements** assess by observing behaviors, like measuring their **reaction times**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "![\"TAM,UTAUT\"](../../Files/third-semester/hai/2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **TAM** is suitable for testing **individual robot-user interactions**.\n",
    "- **UTAUT** is better for evaluating robots in **social or group settings**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **multimodal perception** by McGurk Effect: Visual cues (like lip movements) influence what we hear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Voice Activity Detection (VAD)**: Recognizes when someone is speaking but doesn’t transcribe. Useful for detecting when a robot should start listening.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Artificial Languages**:\n",
    "  - **Engineered Languages**: Designed for **logic, philosophy, or linguistics** experiments (e.g., **Loglan**, **ROILA**).\n",
    "    - **ROILA**: Developed for **HRI** to improve **speech-recognition accuracy**. Words are designed to sound distinct for better recognition by robots. Like \"Go forward\" = **kanek koloke**, \"Go back\" = **kanek nole**.\n",
    "  - **Auxiliary Languages**: Created to **bridge natural languages** or serve as an **international medium** (e.g., **Esperanto**).\n",
    "  - **Artistic Languages**: Made for **fictional worlds** (e.g., **Klingon**, **Elfish**, **Dothraki**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Dialogue Management in HRI**\n",
    "\n",
    "- **Dialogue Management (DM)**:\n",
    "  - **System/User/Mix-initiative**\n",
    "  \n",
    "- **Finite State Machines (FSM)**\n",
    "  \n",
    "- **Event-based DMs** ( More advanced, allowing for dynamic conversation changes based on user input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- Ambivalent(uncertainty) Attitudes Toward Robots: This ambivalence can cause internal conflict and affect how society integrates robots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- HRI Research : Robot and User centered with Iterative Design (Robotic with user feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Research Questions:**\n",
    "    - Exploratory: No pre-hypotheses\n",
    "    - Confirmatory: With hypotheses\n",
    "\n",
    "- **Research Type**\n",
    "    - *Correlation:* Identifies patterns not determine cause (e.g., survey studies).\n",
    "     - *Causation:* Experimental on cause-effect relationship (e.g., randomized control trials).\n",
    "     - *Spurious correlation:* Correlation without Causation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Research Designs:**\n",
    "   - **Between-Subjects Design:** Different groups experience different conditions (e.g., comparing two robot types).\n",
    "   - **Within-Subjects Design:** Same participants experience all conditions.(e.g., multiple robots).\n",
    "   - **Sample Size**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- Variables:\n",
    "    -  Independent Variables (IV)\n",
    "        - Variable that the experimenter **manipulates or changes**\n",
    "        \n",
    "    - Dependent Variables (DV)\n",
    "        - **Definition**: The variable that the experimenter **measures**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- The **independent variable** causes changes.\n",
    "- The **dependent variable** shows the effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- Standards for Statistical Analysis\n",
    "\n",
    "    - **Core Elements**: Tendency (mean), variability (spread), and sample size -> generate p-values.\n",
    "    - **NHST**: Null hypothesis significance testing (NHST) uses the **p-value**\n",
    "    - **Errors**\n",
    "    - **Effect Size**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Socially Interactive Agent (SIA)\n",
    "\n",
    "- No or minimal embodiment\n",
    "    - Chatbots and automated call centers (Siri & Eliza)\n",
    "- Physical embodiment\n",
    "    - social robots with a focus on physical properties (Morphology) like NAO & Pepper\n",
    "- Virtual embodiment\n",
    "    - Intelligent Virtual Agents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Agent Architectures**\n",
    "   - **Sense-Think-Act Cycle**\n",
    "   - **Subsumption Architecture**:\n",
    "     - Hierarchical task-specific modules for continuous behavior (action-reaction).\n",
    "     - Difficult to manage complex behaviors.\n",
    "   - **Layered Architecture**:\n",
    "     - Behavior organized in layers (Reactive, Executive, Deliberative, Reflective).\n",
    "     - Challenges include deciding functionality placement."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

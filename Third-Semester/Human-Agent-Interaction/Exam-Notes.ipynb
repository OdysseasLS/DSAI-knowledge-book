{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ELIZA** -> Chatbot with **pattern-matching rule**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Dialogue Systems**: Frame-Based like **Frame** (slot, slot, slot, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Embodied Conversational Agent**: Computer-generated characters for conversations using verbal and non-verbal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Virtual Character/Human:** Artificial characters with realistic, graphics can convey emotions but may not be interactive or intelligent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Research Process (8 Steps)**:\n",
    "   1. **Research Topic**\n",
    "   2. **Research Question/Hypothesis**\n",
    "   3. **Research Strategy and Experiment Design**:\n",
    "      - Types of research strategies:\n",
    "        - **Descriptive**: Describes current states of variables.\n",
    "        - **Correlational**: Examines relationships between variables.\n",
    "        - **Experimental**: Determines cause-effect relationships by manipulating variables.\n",
    "      - Experiment designs include:\n",
    "         - **within-subjects**: Same participants experience all conditions.\n",
    "         - **between-subjects**: Different participants for each condition.\n",
    "         - **factorial designs**: Tests multiple variables simultaneously.\n",
    "   4. **Operationalizing Variables**: Define variables in measurable terms, ensuring their reliability and validity.\n",
    "   5. **Selecting a Sample**\n",
    "   6. **Data Collection**\n",
    "   7. **Data Processing and Analysis**\n",
    "   8. **Reporting Results I**(ntroduction)**M**(ethods)**R**(esults)a**D**(iscussion) **format)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Study type in SIA Research**:\n",
    "   - **Interviews**\n",
    "   - **Perception-only Studies**: Focus on participants’ perceptions without interaction, often used in early stages of development.\n",
    "   - **Interaction Studies**: Evaluate users interaction with SIAs and measure behavior or outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Virtual Agent Construction**: 3D models, Texture mapping and Shading techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Nonverbal Behavior Representation**\n",
    "   - **Coding Schemes**: FACS (Facial Action Coding System) Breaking facial expressions into muscular movements (AUs or Action Units).\n",
    "   - **Body Coding Systems**: BACS (Body Action Coding System) focuses on body movements and emotions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Models and Approaches**:\n",
    "    - **Rule-based Models**: Use social science rules to create nonverbal behaviors.\n",
    "    - **Performance-based Models**: Rely on human recordings to animate gestures.\n",
    "    - **Machine Learning Models**\n",
    "\n",
    "**Challenges in Multimodal Behavior Modeling**:\n",
    "- Addressing **polysemy**, where a single gesture can have multiple meanings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Rule-based vs. Data-driven Approaches**\n",
    "   - **Rule-based models**: Use predefined rules and linguistic information to generate gestures.\n",
    "      - **Cerebella Architecture**:\n",
    "      - A hybrid system that uses both **acoustic** and **linguistic elements** to dynamically generate gestures with both the speech's auditory cues and its semantic structure.\n",
    "      - Used in both **virtual agent** and **social robotics**.\n",
    "      - Divides its process into stages:\n",
    "      1. Input treatment (text and audio processing).\n",
    "      2. Communicative functions (CFs) like emotion, emphasis analysis.\n",
    "      3. Behavior mapping based on the context.\n",
    "      4. Animation scheduling.\n",
    "\n",
    "      - **GRETA Architecture**:\n",
    "         - Uses **high-level concepts** and external context (e.g., **dialogue goals** or **user moves**) to influence gesture generation by **communicative intentions**\n",
    "      \n",
    "**Workflow**:\n",
    "   1. **User Input**\n",
    "   2. **MIND**: The system processes this input, deciding the agent’s emotional tone and what it should say.\n",
    "   3. **MIDAS**: Adds details to the agent’s response by selecting appropriate gestures and expressions that match the speech.\n",
    "   4. **BODY**: The chosen gestures are generated and timed perfectly with the speech for a natural response.\n",
    "   5. **User Model & Context Features**: Throughout, the system considers the user's preferences, reactions, and the external context to tailor the response, ensuring it fits the conversation setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Moravec’s Paradox**: Machines perform complex tasks, but simple tasks like those a child can do are extremely difficult for robots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- Transfer learning = fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- Pareidolia: Pareidolia is seeing humanlike features in random objects, like a face on Mars.\n",
    "\n",
    "- **Frankenstein approach** builds robots by focusing on technology first, then adding appearance and social features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Morphology** prioritizes a robot's practical design for specific tasks over appearance.\n",
    "- **Anthropomorphism** focuses on adding human-like features and behaviors to enhance social interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Design Patterns**: Reusable solutions to common problems in HRI design, such as communication patterns, can be applied across different robot designs.\n",
    "    - **Underpromise and Overdeliver**: Set realistic expectations to avoid disappointment; don’t overhype a robot’s abilities.\n",
    "    - **Interaction Expands Function**: `Open-ended` design allows users to adapt the robot to their own needs and expectations.\n",
    "    - **Do Not Mix Metaphors**: Keep design consistent—appearance and behavior should align to avoid discomfort or confusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Engineering Design Process**: Emphasizes technical problem-solving through simulations, but is limited in open-ended contexts.\n",
    "- **User-Centered Design (UCD)**: Involves users to ensure designs meet their needs, with early prototype testing.\n",
    "- **Participatory Design**: Collaborative approach where users co-create designs, essential for specific groups like the elderly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Measuring Anthropomorphization**:\n",
    "   - **Explicit measurements** involve directly asking people about their perceptions.\n",
    "      - **Mind perception**: assess people believe a robot has **agency** (the ability to act intentionally) and **experience** (the ability to feel emotions).\n",
    "      - **Warmth and competence**: how friendly (warm) and capable (competent) they are.\n",
    "      - The **Godspeed Questionnaire**: evaluate human-robot interaction through five key dimensions:\n",
    "         - **Anthropomorphism** – How human-like the robot appears.\n",
    "         - **Animacy** – How \"alive\" or animated the robot seems.\n",
    "         - **Likeability**\n",
    "         - **Intelligence**\n",
    "         - **Safety** – How safe the person feels interacting with the robot.\n",
    "\n",
    "   - **Implicit measurements** assess by observing behaviors, like measuring their **reaction times**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "![\"TAM,UTAUT\"](../../Files/third-semester/hai/2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **TAM** is suitable for testing **individual robot-user interactions**.\n",
    "- **UTAUT** is better for evaluating robots in **social or group settings**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **multimodal perception** by McGurk Effect: Visual cues (like lip movements) influence what we hear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Voice Activity Detection (VAD)**: Recognizes when someone is speaking but doesn’t transcribe. Useful for detecting when a robot should start listening.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Artificial Languages**:\n",
    "  - **Engineered Languages**: Designed for **logic, philosophy, or linguistics** experiments (e.g., **Loglan**, **ROILA**).\n",
    "    - **ROILA**: Developed for **HRI** to improve **speech-recognition accuracy**. Words are designed to sound distinct for better recognition by robots. Like \"Go forward\" = **kanek koloke**, \"Go back\" = **kanek nole**.\n",
    "  - **Auxiliary Languages**: Created to **bridge natural languages** or serve as an **international medium** (e.g., **Esperanto**).\n",
    "  - **Artistic Languages**: Made for **fictional worlds** (e.g., **Klingon**, **Elfish**, **Dothraki**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Dialogue Management in HRI**\n",
    "\n",
    "- **Dialogue Management (DM)**:\n",
    "  - **System/User/Mix-initiative**\n",
    "  \n",
    "- **Finite State Machines (FSM)**\n",
    "  \n",
    "- **Event-based DMs** ( More advanced, allowing for dynamic conversation changes based on user input)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ELIZA** -> Chatbot with **pattern-matching rule**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Dialogue Systems**: Frame-Based like **Frame** (slot, slot, slot, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Embodied Conversational Agent**: Computer-generated characters for conversations using verbal and non-verbal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Virtual Character/Human:** Artificial characters with realistic, graphics can convey emotions but may not be interactive or intelligent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Research Process (8 Steps)**:\n",
    "   1. **Research Topic**\n",
    "   2. **Research Question/Hypothesis**\n",
    "   3. **Research Strategy and Experiment Design**:\n",
    "      - Types of research strategies:\n",
    "        - **Descriptive**: Describes current states of variables.\n",
    "        - **Correlational**: Examines relationships between variables.\n",
    "        - **Experimental**: Determines cause-effect relationships by manipulating variables.\n",
    "      - Experiment designs include:\n",
    "         - **within-subjects**: Same participants experience all conditions.\n",
    "         - **between-subjects**: Different participants for each condition.\n",
    "         - **factorial designs**: Tests multiple variables simultaneously.\n",
    "   4. **Operationalizing Variables**: Define variables in measurable terms, ensuring their reliability and validity.\n",
    "   5. **Selecting a Sample**\n",
    "   6. **Data Collection**\n",
    "   7. **Data Processing and Analysis**\n",
    "   8. **Reporting Results I**(ntroduction)**M**(ethods)**R**(esults)a**D**(iscussion) **format)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Study type in SIA Research**:\n",
    "   - **Interviews**\n",
    "   - **Perception-only Studies**: Focus on participants’ perceptions without interaction, often used in early stages of development.\n",
    "   - **Interaction Studies**: Evaluate users interaction with SIAs and measure behavior or outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Virtual Agent Construction**: 3D models, Texture mapping and Shading techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Nonverbal Behavior Representation**\n",
    "   - **Coding Schemes**: FACS (Facial Action Coding System) Breaking facial expressions into muscular movements (AUs or Action Units).\n",
    "   - **Body Coding Systems**: BACS (Body Action Coding System) focuses on body movements and emotions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Models and Approaches**:\n",
    "    - **Rule-based Models**: Use social science rules to create nonverbal behaviors.\n",
    "    - **Performance-based Models**: Rely on human recordings to animate gestures.\n",
    "    - **Machine Learning Models**\n",
    "\n",
    "**Challenges in Multimodal Behavior Modeling**:\n",
    "- Addressing **polysemy**, where a single gesture can have multiple meanings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Rule-based vs. Data-driven Approaches**\n",
    "   - **Rule-based models**: Use predefined rules and linguistic information to generate gestures.\n",
    "      - **Cerebella Architecture**:\n",
    "      - A hybrid system that uses both **acoustic** and **linguistic elements** to dynamically generate gestures with both the speech's auditory cues and its semantic structure.\n",
    "      - Used in both **virtual agent** and **social robotics**.\n",
    "      - Divides its process into stages:\n",
    "      1. Input treatment (text and audio processing).\n",
    "      2. Communicative functions (CFs) like emotion, emphasis analysis.\n",
    "      3. Behavior mapping based on the context.\n",
    "      4. Animation scheduling.\n",
    "\n",
    "      - **GRETA Architecture**:\n",
    "         - Uses **high-level concepts** and external context (e.g., **dialogue goals** or **user moves**) to influence gesture generation by **communicative intentions**\n",
    "      \n",
    "**Workflow**:\n",
    "   1. **User Input**\n",
    "   2. **MIND**: The system processes this input, deciding the agent’s emotional tone and what it should say.\n",
    "   3. **MIDAS**: Adds details to the agent’s response by selecting appropriate gestures and expressions that match the speech.\n",
    "   4. **BODY**: The chosen gestures are generated and timed perfectly with the speech for a natural response.\n",
    "   5. **User Model & Context Features**: Throughout, the system considers the user's preferences, reactions, and the external context to tailor the response, ensuring it fits the conversation setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Moravec’s Paradox**: Machines perform complex tasks, but simple tasks like those a child can do are extremely difficult for robots."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

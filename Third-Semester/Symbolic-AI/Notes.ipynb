{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Artificial General Intelligence :** reasoning, learning, problem solving, generalisation\n",
    "\n",
    "**Strong AI:** Machines that act intelligently can eventually also possess consciousness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swarm intelligence: agents interacting locally with one another and with the environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical (Symbolic) AI or Good Old-fashioned AI (GOFAI)\n",
    "\n",
    "focusses on knowledge representation and general purpose “reasoning” mechanisms.\n",
    "\n",
    "- Separation between knowledge and reasoning.\n",
    "- Generic reasoning (problem-solving) based on search and logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Environment Properties:**\n",
    "- **Deterministic:** The next state is entirely predictable from the current state and action (e.g., a puzzle game like Tetris).\n",
    "- **Stochastic:** There is some randomness in the outcome of actions (e.g., Pacman, where ghosts can move unpredictably)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Types of Agents:**\n",
    "\n",
    "1. **Simple Reflex Agents:**\n",
    "   - Act on current percepts using predefined condition–action rules.\n",
    "   - Limitations: Fail in partially observable environments.\n",
    "\n",
    "2. **Model-Based Reflex Agents:**\n",
    "   - Handle **partially observable environments** by maintaining an internal state.\n",
    "\n",
    "3. **Goal-based Agents:**\n",
    "4. **Utility-based Agents:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **Task Environments (PEAS Framework)**\n",
    "- **PEAS:** Performance measure, Environment, Actuators, Sensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Graph vs. Tree Search**\n",
    "- **Tree Search**: Considers all paths, including loops.\n",
    "- **Graph Search**: Avoids revisiting states by using an explored set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Uninformed Search**: No additional information about states beyond the problem definition.\n",
    "- **Informed Search**: Uses heuristics to estimate the quality of non-goal states (covered in Section 3.5).\n",
    "\n",
    "## Uninformed Search Methods\n",
    "\n",
    "Don’t have prior knowledge of the problem domain.\n",
    "\n",
    "- **Breadth-first search**\n",
    "- **Uniform-cost search**: Expands the node with the lowest path cost, $g(n)$, and is optimal for general step costs.\n",
    "Memory efficient, time efficient\n",
    "```bash\n",
    "    A\n",
    "   / \\\n",
    "  2   3\n",
    " /     \\\n",
    "B       C    \n",
    "|\\     /|\n",
    "4 1   2 5\n",
    "|  \\ /  |\n",
    "D   E   F\n",
    " \\  |  /\n",
    "  \\ | /\n",
    "   \\|/\n",
    "    G   \n",
    "```\n",
    "Steps:\n",
    "1. `(A, cost=0)`,              2. `[(B, cost=2), (C, cost=3)]`,             3. `[(C, cost=3), (E, cost=3), (D, cost=6)]`\n",
    "4. `[(E, cost=3), (D, cost=6), (E, cost=5), (F, cost=8)]`,    5. `[(D, cost=6), (E, cost=5), (F, cost=8), (G*, cost=4)]`\n",
    "\n",
    "- **Depth-first search**\n",
    "- **Iterative deepening search**: \n",
    "```bash\n",
    "        A\n",
    "       / \\\n",
    "      B   C\n",
    "     / \\   \\\n",
    "    D   E   G\n",
    "\n",
    "```\n",
    "Depth = 0 :`A`, Depth = 1 :`A → B, A → C`, Depth = 2 :`A → B → D, A → B → E, A → C → G`\n",
    "- **Bidirectional search**: Can enormously reduce time complexity, but it is not always applicable and may require too much space.\n",
    "\n",
    "## Informed Search Methods\n",
    "\n",
    "Informed search methods may have access to a heuristic function $h(n)$ that estimates the cost of a solution from $n$.\n",
    "\n",
    "- **Best-first search**: A generic algorithm that selects a node for expansion according to an evaluation function.\n",
    "- **Greedy best-first search**: Expands nodes with minimal $h(n)$. It is not optimal but is often efficient.\n",
    "- **A\\* search**: Expands nodes with minimal $f(n) = g(n) + h(n)$. \n",
    "  - A\\* is complete and optimal, provided that $h(n)$ is admissible (for Tree-Search) or consistent (for Graph-Search). \n",
    "  - However, the space complexity of A\\* is still prohibitive.\n",
    "  - <img src=\"https://d18l82el6cdm1i.cloudfront.net/uploads/hevQ7EbwVU-output_prgol9.gif\" alt=\"Breadth-First Search\" width=\"250\">\n",
    "- **RBFS (Recursive Best-First Search)** and **SMA\\* (Simplified Memory-Bounded A\\*)**: Robust, optimal search algorithms that use limited amounts of memory. Given enough time, they can solve problems that A\\* cannot solve due to memory constraints.\n",
    "\n",
    "## Heuristic Search Performance\n",
    "\n",
    "The performance of heuristic search algorithms depends on the quality of the heuristic function. Good heuristics can be constructed by:\n",
    "- Relaxing the problem definition.\n",
    "- Storing precomputed solution costs for subproblems in a **pattern database**.\n",
    "- Learning from experience with the problem class.\n",
    "\n",
    "\n",
    "- **BFS and UCS** are exhaustive but memory-intensive.\n",
    "- **DFS and DLS** save memory but risk incompleteness.\n",
    "- **IDS** combines benefits of BFS and DFS for large state spaces.\n",
    "- **Bidirectional Search** is efficient but requires a well-defined goal state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Admissible vs. Consistent Heuristics**\n",
    "- **Admissible**: Never overestimates the cost to the goal.  \n",
    "- **Consistent**: Satisfies the triangle inequality ($ h(n) \\leq c(n, a, n') + h(n') $)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "| Criterion        | Breadth-First      | Uniform-Cost          | Depth-First | Depth-Limited | Iterative Deepening | Bidirectional (if applicable) |\n",
    "|------------------|--------------------|------------------------|-------------|---------------|---------------------|-------------------------------|\n",
    "| **Complete?**    | Yes $^a$           | Yes $^{a,b}$           | No          | No            | Yes $^a$            | Yes $^{a,d}$                  |\n",
    "| **Time**         | $O(b^d)$          | $O(b^{1+C^*/\\epsilon})$ | $O(b^m)$    | $O(b^\\ell)$   | $O(b^d)$           | $O(b^{d/2})$                 |\n",
    "| **Space**        | $O(b^d)$          | $O(b^{1+C^*/\\epsilon})$ | $O(bm)$     | $O(b^\\ell)$   | $O(bd)$            | $O(b^{d/2})$                 |\n",
    "| **Optimal?**     | Yes $^c$           | Yes                   | No          | No            | Yes $^c$            | Yes $^{c,d}$                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Local Search Methods:**\n",
    "     - **Hill Climbing:** A greedy approach that moves towards increasing value but can get stuck at local maxima, ridges, or plateaus.\n",
    "     - **Simulated Annealing:** Allows downhill moves probabilistically to escape local maxima, with the probability decreasing as the \"temperature\" decreases over time.\n",
    "\n",
    "4. **Nondeterministic Environments:**\n",
    "   - Require **AND–OR search trees** to handle contingencies.\n",
    "\n",
    "5. **Partially Observable Environments:**\n",
    "   - Use **belief states** to represent the agent’s knowledge about the possible physical states it could be in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Methods:\n",
    "\n",
    "**Model Checking:** Enumerates all possible models to verify entailment. Simple and guarantees correctness but computationally expensive ($ O(2^n) $) for large KBs.\n",
    "\n",
    "**Logical Inference:** Uses rules like **Modus Ponens** and **Resolution** to derive new sentences.\n",
    "\n",
    "**Resolution:** A single, powerful inference rule for CNF sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **- Boolean/Propositional logic**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert Propositional Logic to CNF:\n",
    "1. **Eliminate Implications (⇒)**:\n",
    "   - `A ⇒ B` becomes `¬A ∨ B`.\n",
    "2. **Move NOTs (`¬`) Inside** (De Morgan's Laws):\n",
    "   - `¬(A ∨ B)` becomes `¬A ∧ ¬B`.\n",
    "   - `¬(A ∧ B)` becomes `¬A ∨ ¬B`.\n",
    "3. **Distribute OR (`∨`) Over AND (`∧`)**:\n",
    "   - `(A ∧ B) ∨ C` becomes `(A ∨ C) ∧ (B ∨ C)`.\n",
    "\n",
    "#### **Definite Clauses**\n",
    "- Form: `(A ∧ B ∧ …) ⇒ C` or `¬A ∨ ¬B ∨ … ∨ C`.\n",
    "- Advantage:\n",
    "  - Simplifies chaining proofs.\n",
    "  - Human-readable format.\n",
    "\n",
    "\n",
    "#### **Horn Clauses:**\n",
    "- A special subset of CNF with at most one positive literal.\n",
    "- Used in efficient inference methods (e.g., forward/backward chaining)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **First order logic**:\n",
    "- Representation of **objects**, **relations**, and **facts** with **quantifiers** $∀x ∃y$ relation $(x, y)$.\n",
    "\n",
    "#### **FOL Reduction to Propositional Logic**\n",
    "1. **Universal Instantiation**:\n",
    "   - Drop (`∀`) and replace the variable with a specific object.\n",
    "\n",
    "2. **Existential Instantiation**:\n",
    "   - Replace (`∃`) with a **Skolem constant** (Just write C).\n",
    "\n",
    "#### **Resolution in First-Order Logic**\n",
    "1. **Convert FOL to CNF**\n",
    "\n",
    "2. **Negate the Query**\n",
    "\n",
    "3. **Apply Resolution**\n",
    "\n",
    "4. **Contradiction → Query Proven**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "#### **Example:**\n",
    "**Knowledge Base (KB):**\n",
    "- `∀y (∃x owns(y, x) ⇒ hasProperty(y))`\n",
    "- `owns(joost, house)`\n",
    "\n",
    "**Query**: Prove `hasProperty(joost)`.\n",
    "\n",
    "\n",
    "#### **Step-by-Step Solution:**\n",
    "1. **Convert KB to CNF**:\n",
    "   - `∀y (∃x owns(y, x) ⇒ hasProperty(y))`\n",
    "   - Eliminate `⇒`: `∀y (¬∃x owns(y, x) ∨ hasProperty(y))`.\n",
    "   - Move `¬` inside: `∀y ∀x (¬owns(y, x) ∨ hasProperty(y))`.\n",
    "   - Skolemize: `¬owns(y, f(y)) ∨ hasProperty(y)` (replace `∃x` with Skolem function `f(y)`).\n",
    "   - CNF: `¬owns(y, f(y)) ∨ hasProperty(y)`.\n",
    "\n",
    "2. **Add Query Negation**:\n",
    "   - Add `¬hasProperty(joost)` to KB.\n",
    "\n",
    "3. **Resolution**:\n",
    "   - Unify `y = joost` and resolve:\n",
    "     - From KB: `¬owns(joost, f(joost)) ∨ hasProperty(joost)`\n",
    "     - Negation: `¬hasProperty(joost)`\n",
    "   - Resolving gives `¬owns(joost, f(joost))`.\n",
    "   - Unify `owns(joost, house)` with `¬owns(joost, f(joost))` (substituting `f(joost) = house`).\n",
    "   - Contradiction: `owns(joost, house)` and `¬owns(joost, house)`.\n",
    "\n",
    "4. **Conclusion**:\n",
    "   - Contradiction proves the query: `hasProperty(joost)` is **true**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Local Search Methods:**\n",
    "   - Operate on **complete-state formulations**, retaining only a small number of nodes in memory.\n",
    "   - Methods include:\n",
    "     - **Hill Climbing:** A greedy approach that moves towards increasing value but can get stuck at local maxima, ridges, or plateaus.\n",
    "     - **Simulated Annealing:** Allows downhill moves probabilistically to escape local maxima, with the probability decreasing as the \"temperature\" decreases over time.\n",
    "   - Effective for **optimization problems** like the 8-queens puzzle, where the path to the solution is irrelevant.\n",
    "\n",
    "2. **Continuous Search Spaces:**\n",
    "   - Problems such as linear programming and convex optimization involve continuous variables and often admit **polynomial-time algorithms**.\n",
    "   - Techniques include **gradient descent** and the **Newton–Raphson method**, which exploit mathematical properties of smooth functions.\n",
    "\n",
    "3. **Genetic Algorithms:**\n",
    "   - Inspired by evolutionary biology, they maintain a population of states and evolve them using mutation, crossover, and selection.\n",
    "   - Useful for problems like the traveling salesperson problem (TSP).\n",
    "\n",
    "4. **Nondeterministic Environments:**\n",
    "   - Require **AND–OR search trees** to handle contingencies.\n",
    "   - Solutions are **contingent plans** rather than sequences, specifying actions for all possible outcomes.\n",
    "\n",
    "5. **Partially Observable Environments:**\n",
    "   - Use **belief states** to represent the agent’s knowledge about the possible physical states it could be in.\n",
    "   - **Sensorless problems** rely on actions to coerce the environment into a goal state.\n",
    "   - Algorithms such as **belief-state AND–OR search** or **incremental belief-state search** are applied to these environments.\n",
    "\n",
    "6. **Exploration and Online Search:**\n",
    "   - Online agents interleave computation and execution, making them suited for **dynamic and unknown environments**.\n",
    "   - Algorithms include:\n",
    "     - **Online Depth-First Search (DFS):** Explores the state space systematically but requires reversibility of actions.\n",
    "     - **Learning Real-Time A\\* (LRTA\\*):** Updates heuristic estimates during exploration to improve decisions and escape local minima.\n",
    "\n",
    "7. **Heuristic Improvements:**\n",
    "   - Agents can update heuristic values during search, enabling more efficient exploration.\n",
    "   - Random restarts and simulated annealing help tackle local minima in large state spaces.\n",
    "\n",
    "---\n",
    "\n",
    "1. **Special Cases of Algorithms:**\n",
    "   - Local beam search (k = 1): **Hill climbing.**\n",
    "   - Beam search with no state limit: **Breadth-first search.**\n",
    "   - Simulated annealing with T = 0: **Greedy search.**\n",
    "   - Simulated annealing with T = ∞: **Random walk.**\n",
    "   - Genetic algorithm with N = 1: **Random restart hill climbing.**\n",
    "\n",
    "2. **Formulating Problems for Simulated Annealing:**\n",
    "   - Example: Real-world railway track alignment allows slight misalignments. Represent states as track configurations and the cost as the degree of misalignment. Neighboring states correspond to small rotations.\n",
    "\n",
    "3. **Hill Climbing and Genetic Algorithms for TSP:**\n",
    "   - Hill climbing explores neighboring cities, comparing solutions to A\\* with the MST heuristic.\n",
    "   - Genetic algorithms use crossover and mutation to evolve paths.\n",
    "\n",
    "4. **Evaluating Local Search Variants:**\n",
    "   - Generate problem instances for the 8-puzzle and 8-queens problems.\n",
    "   - Analyze performance metrics (e.g., success rate, search cost).\n",
    "\n",
    "5. **Improving AND–OR Search:**\n",
    "   - Use state labels to track previously visited states and avoid redundant computation.\n",
    "   - Allow cyclic plans for slippery or erratic environments.\n",
    "\n",
    "6. **Belief State Optimization:**\n",
    "   - Sensorless problems: Use heuristics like $ h(b) = \\min_{s \\in b} h^*(s) $, ensuring admissibility.\n",
    "   - Subset-superset relationships enable pruning of belief states during search.\n",
    "\n",
    "7. **Online Search Challenges:**\n",
    "   - Represent the initial belief state as all possible configurations.\n",
    "   - Generate contingency plans that adapt to all observations.\n",
    "\n",
    "8. **Advanced Problem Solving:**\n",
    "   - Use online agents to navigate dynamic environments, handling errors and replanning.\n",
    "   - Modify hill climbing with depth-k lookahead or LRTA\\* to escape local minima.\n",
    "\n",
    "9. **Infinite State Spaces:**\n",
    "   - Online DFS is incomplete for infinite reversible spaces. A complete algorithm must dynamically track and prioritize unvisited states.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

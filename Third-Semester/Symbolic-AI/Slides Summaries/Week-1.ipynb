{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding and consciousness: Human biological brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intelligent behavior does not imply the machine is conscious and understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, machines can be intelligent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Artificial General Intelligence :** reasoning, learning, problem solving, generalisation\n",
    "\n",
    "**Strong AI:** Machines that act intelligently can eventually also possess consciousness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Different approaches to AI:\n",
    "\n",
    "1. **Classic AI**: (Focus on model structure, formalism and architecture)\n",
    "    - Agent-based reasoning\n",
    "    - Utilizes search, logic, and rule-based systems\n",
    "    - Symbol manipulation\n",
    "    - Includes agents, environments, and memory\n",
    "\n",
    "2. **Machine Learning**\n",
    "\n",
    "3. **Cognitive Science/Cognitive Modelling**: (Focus on model structure, formalism and architecture)\n",
    "    - Replicating psychological and biological mechanisms that lead to intelligent behavior\n",
    "    - Utilizes frameworks like ACT-R and SOAR.\n",
    "\n",
    "4. **Computational Intelligence/Natural Computing:** (More Biological Approach, Focus on model outputs behavior and solution)\n",
    "    - Draws inspiration from biological systems for search and optimization\n",
    "    - Includes techniques like swarm intelligence* and genetic algorithms.\n",
    "\n",
    "*Swarm intelligence: agents interacting locally with one another and with the environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Classical (Symbolic) AI or Good Old-fashioned AI (GOFAI)\n",
    "\n",
    "focusses on knowledge representation and general purpose “reasoning” mechanisms.\n",
    "\n",
    "- Separation between knowledge and reasoning.\n",
    "- Generic reasoning (problem-solving) based on search and logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Rational agent** = an agent program that chooses actions such\n",
    "that for any given percept sequence the expectation of\n",
    "payoff for an action is maximal according to some pay-off\n",
    "function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Approaches to AI\n",
    "- **Classical AI**: Rule-based reasoning and logic.\n",
    "- **Machine Learning**: Data-driven approach with minimal domain knowledge.\n",
    "- **Cognitive Modeling**: Mimics biological and psychological mechanisms.\n",
    "- **Computational Intelligence**: Inspired by biology (e.g., genetic algorithms, swarm intelligence).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "### **Environment Properties:**\n",
    "These describe the nature of the world the agent interacts with.\n",
    "\n",
    "1. **Fully Observable vs. Partially Observable:**\n",
    "   - **Fully Observable:** The agent can see everything it needs to make a decision (e.g., Tic Tac Toe: you can see the entire board).\n",
    "   - **Partially Observable:** The agent can't see the entire environment (e.g., in a game like Stratego, you can’t see all of your opponent’s pieces).\n",
    "\n",
    "2. **Single Agent vs. Multi-Agent:**\n",
    "   - **Single Agent:** Only one agent is making decisions (e.g., Solitaire).\n",
    "   - **Multi-Agent:** Multiple agents interact, which can be competitive (e.g., Tic Tac Toe) or cooperative (e.g., multiplayer games).\n",
    "\n",
    "3. **Deterministic vs. Stochastic:**\n",
    "   - **Deterministic:** The next state is entirely predictable from the current state and action (e.g., a puzzle game like Tetris).\n",
    "   - **Stochastic:** There is some randomness in the outcome of actions (e.g., Pacman, where ghosts can move unpredictably).\n",
    "\n",
    "4. **Episodic vs. Sequential:**\n",
    "   - **Episodic:** Each action is independent of previous ones (e.g., a game where every round resets).\n",
    "   - **Sequential:** Actions are connected, and decisions in earlier steps affect future outcomes (e.g., Mario Bros).\n",
    "\n",
    "5. **Static vs. Dynamic:**\n",
    "   - **Static:** The environment only changes when the agent acts (e.g., Chess, where the board stays the same until a move is made).\n",
    "   - **Dynamic:** The environment changes on its own, regardless of the agent’s actions (e.g., Pacman, where ghosts move around even if Pacman doesn’t).\n",
    "\n",
    "6. **Discrete vs. Continuous:**\n",
    "   - **Discrete:** The environment has a limited set of distinct states or actions (e.g., Tic Tac Toe has a fixed number of moves).\n",
    "   - **Continuous:** There are infinite possibilities for states or actions (e.g., controlling a car in a racing game).\n",
    "\n",
    "7. **Known Model vs. Learned Model:**\n",
    "   - **Known Model:** The agent already knows how its actions will affect the environment (e.g., an experienced driver who knows how turning the wheel affects the car).\n",
    "   - **Learned Model:** The agent has to learn the effects of its actions over time (e.g., a beginner learning to drive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "### **Types of Agents:**\n",
    "\n",
    "1. **Reflexive Agents:**\n",
    "   - These agents react directly to current perceptions without thinking about the past or the future.\n",
    "   - Example: In Tic Tac Toe, if the other player puts an “X” in the middle, the reflexive agent always responds by putting an “O” in a specific corner.\n",
    "   - **Limitations:** These agents don’t store history, so they may make poor decisions, like making illegal moves.\n",
    "\n",
    "2. **Model-based Reflexive Agents:**\n",
    "   - These agents remember past states (percepts) to make better decisions.\n",
    "   - Example: The agent remembers that it placed an “O” in a specific spot earlier and won’t place another piece there.\n",
    "   - **Benefit:** Solves issues of illegal or irrational moves by using memory.\n",
    "   - **Limitation:** Can’t plan ahead to win; it just reacts.\n",
    "\n",
    "3. **Goal-based Agents:**\n",
    "   - These agents have specific goals and plan actions to reach those goals.\n",
    "   - Example: In Tic Tac Toe, the agent plans moves to create a row of three “O”s and win the game.\n",
    "   - **Benefit:** They can plan steps to reach a goal.\n",
    "   - **Limitation:** If there are multiple goals or paths, it’s harder to decide the best one.\n",
    "\n",
    "4. **Utility-based Agents:**\n",
    "   - These agents consider not just goals but also the value (utility) of different outcomes and actions.\n",
    "   - Example: An agent that knows winning is worth more than a draw and makes moves that maximize its chance of winning.\n",
    "   - **Benefit:** They make more sophisticated decisions by considering the desirability of different outcomes.\n",
    "   - **Limitation:** Calculating utilities for all possible outcomes can be complex.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "### **Knowledge Representation:**\n",
    "\n",
    "1. **Atomic Representation:**\n",
    "   - Each state is represented as a single symbol without any internal structure.\n",
    "   - Example: In Tic Tac Toe, the entire board could be represented by a single number, like “5” to describe the state of the game.\n",
    "   - **Limitation:** There’s no way to compare states or make detailed decisions.\n",
    "\n",
    "2. **Factorial Representation:**\n",
    "   - A state is represented as a set of features, and each feature can have a value.\n",
    "   - Example: In Tic Tac Toe, the state could be represented by the presence or absence of an “X” or “O” in each square. Each square could be a Boolean (true/false) value.\n",
    "   - **Benefit:** You can compare states based on their features (e.g., does one square have an “X” while another has an “O”?).\n",
    "   - **Limitation:** Only captures predefined features, so it's less flexible.\n",
    "\n",
    "3. **Structural Representation:**\n",
    "   - States are represented as objects and their relationships, similar to how humans think.\n",
    "   - Example: In Tic Tac Toe, instead of just marking squares, you could describe relationships like \"there are two ‘O’s in a row in the top row.\"\n",
    "   - **Benefit:** This allows for more complex reasoning, similar to human thought processes.\n",
    "   - **Limitation:** It can be more complex to implement and manage.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planning key difference with inference\n",
    "- Actions have effects on the knowledge base\n",
    "\n",
    "- They change things over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### **Planning domain description language (PDDL)**\n",
    "\n",
    "• A way to write down actions and their effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- **Structure**:\n",
    "  - **Action**: `Action(predicate(...))`.\n",
    "  - **Preconditions**: Conditions that must hold true before the action can be executed (e.g., `predicate(...)`).\n",
    "  - **Postconditions**:\n",
    "    - **Add effects**: Conditions that become true after the action (`Add(a)`).\n",
    "    - **Delete effects**: Conditions that are no longer true after the action (`Del(a)`).\n",
    "  - **Action effects**:\n",
    "    - Formula: `Result(s, a) = (s - Del(a)) ∪ Add(a)`.\n",
    "    - `s`: Current state, `a`: Action.\n",
    "\n",
    "\n",
    "#### **Example: Blocksworld**\n",
    "\n",
    "### Initial State (Left):\n",
    "```\n",
    "    [A]\n",
    "    [B]   [C]\n",
    "  ---------\n",
    "```\n",
    "### Goal State (Right):\n",
    "```\n",
    "    [C]\n",
    "    [A]\n",
    "    [B]\n",
    "  ---------\n",
    "```\n",
    "\n",
    "**Initial State:**  \n",
    "`on(a, b), on(b, table), on(c, table), clear(a), clear(c)`\n",
    "\n",
    "**Goal State:**  \n",
    "`on(c, a), on(a, b), on(b, table)`\n",
    "\n",
    "**Actions:**  \n",
    "- **move(block, from, to):**  \n",
    "  - *Pre:* `on(block, from), clear(block), clear(to), block != to, block != from, from != to`  \n",
    "  - *Post:* `on(block, to), -on(block, from), clear(from), -clear(to)`  \n",
    "\n",
    "- **moveToTable(block, from):**  \n",
    "  - *Pre:* `clear(block), on(block, from), block != from`  \n",
    "  - *Post:* `on(block, table), clear(from), -on(block, from)`\n",
    "\n",
    "### **Planning Workflow**\n",
    "1. **Initial State**:\n",
    "   - Define the current conditions of the environment.\n",
    "2. **Goal State**:\n",
    "   - Specify the desired conditions after planning.\n",
    "3. **Actions**:\n",
    "   - Write actions with preconditions and effects using PDDL.\n",
    "4. **Plan Generation**:\n",
    "   - Use AI algorithms (e.g., **state-space search**, **heuristic search**) to find a sequence of actions that transitions the system from the initial state to the goal state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---\n",
    "\n",
    "### Planning Algorithms\n",
    "\n",
    "#### **Forward Progression**\n",
    "- Keep firing action rules until the goal state is achieved.\n",
    "- Process:\n",
    "  - Match preconditions, apply postconditions:  \n",
    "    `s' = (s - Del(a)) U Add(a)`\n",
    "- Can use algorithms like Depth-First Search, Breadth-First Search, or A*.\n",
    "\n",
    "#### **Backward Regression**\n",
    "- Start from the goal state and apply \"inverse\" postconditions.\n",
    "- Process:\n",
    "  - Instantiate action rules with the goal state:  \n",
    "    `s' = (s - Add(a)) U preconditions(a)`\n",
    "\n",
    "\n",
    "#### **Forward Search**\n",
    "- Issue: **Redundant states**\n",
    "  A method where you start from the initial state and keep applying actions (**preconditions, postconditions**)  until you reach the goal state. It can be **inefficient** because it tries **every possible action** without focusing on what’s important.\n",
    "\n",
    "#### **Backward Search**\n",
    "- Issue: **Non-determinism**\n",
    "  - Can't account for `Del(a)`, so the previous state isn't fully known.\n",
    "  - Need to track **state sets** during regression.\n",
    "  - If `Del(a)` is a postcondition:\n",
    "    - `a` could be true or false in the previous round.\n",
    "    - Introduces **non-determinism**.\n",
    "\n",
    "#### **Most Planners**\n",
    "- Prefer **forward search**.\n",
    "- Aim to reduce the **branching factor** of the reachability graph.\n",
    "\n",
    "---\n",
    "\n",
    "### **Graphplan: Forward Search with Heuristics**\n",
    "\n",
    "A smarter version of forward search that uses a **planning graph** to make the search more efficient.\n",
    "\n",
    "- **Planning Graph Features:**  \n",
    "  1. **Tracks Reachability:**  \n",
    "     - It shows which actions are possible from the current state.\n",
    "     - It also shows which literals (conditions) can be true at each step.\n",
    "\n",
    "  2. **Uses Mutex Relations:**  \n",
    "     - A \"mutex\" (mutual exclusion) identifies **conflicts** between actions or conditions, so it avoids wasting time on impossible plans.  \n",
    " \n",
    "\n",
    "  3. **Persistency Actions (No-op):**  \n",
    "     - Adds \"do nothing\" actions to keep conditions (literals) true when no action changes them.  \n",
    "\n",
    "- **How it Helps:**  \n",
    "  - The planning graph gives a **polynomial-time way** to check what is possible.  \n",
    "  - It **prunes irrelevant actions** and reduces the number of possibilities the algorithm has to explore.  \n",
    "\n",
    "- **Still Exponential:**  \n",
    "  While the actual search for a solution still requires exponential time, **Graphplan** reduces the branching factor (the number of options at each step), making the search faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "![Graph](../../../Files/third-semester/sai/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Planning and Goal-Oriented Agents**\n",
    "\n",
    "#### **Other Ways of Making Plans**\n",
    "1. **Using Knowledge Representation:**\n",
    "   - **Reduction to propositional logic:** Represent planning as a logical problem to solve using propositional formulas.\n",
    "   - **Reduction to predicate logic (situation calculus):** Use first-order logic to describe situations and changes.\n",
    "   - **Constraint satisfaction:** Treat planning as a problem of finding values for variables that meet constraints.\n",
    "\n",
    "2. **Without Knowledge Representation:**\n",
    "   - Assume the agent’s **knowledge base (KB)** is an atomic state.\n",
    "   - Use **standard tree search algorithms**, checking at each node if the goal predicates are provable.\n",
    "\n",
    "---\n",
    "\n",
    "### **Goal-Oriented Agents**\n",
    "1. **Characteristics:**\n",
    "   - Select sequences of actions to achieve a goal state.\n",
    "   - Operate in real-world environments:\n",
    "     - **Partial knowledge:** Do not have a full description of the world.\n",
    "     - **Sensors:** Perceive parts of the world.\n",
    "     - **Actions:** Can interact with the environment but may fail.\n",
    "\n",
    "2. **Requirements:**\n",
    "   - Need a detailed representation of their mental state (facts, goals, and intentions).\n",
    "   - Require more complex rule execution and reasoning.\n",
    "\n",
    "---\n",
    "\n",
    "### **BDI Architecture** (Belief-Desire-Intention)\n",
    "1. **Belief Base:**  \n",
    "   - Facts known to the agent.  \n",
    "   - Example: The agent knows it is at location X.\n",
    "\n",
    "2. **Desires Base:**  \n",
    "   - Goals the agent wants to achieve.  \n",
    "   - Example: The agent desires to reach location Y.\n",
    "\n",
    "3. **Intention Base:**  \n",
    "   - Actions the agent can execute based on its goals and preconditions.  \n",
    "   - Example: Move from X to Y.\n",
    "\n",
    "---\n",
    "\n",
    "### **Agent Program Structure**\n",
    "1. **Percept Rules:**\n",
    "   - Triggered when the agent senses the world.\n",
    "   - Add new facts to the belief base.\n",
    "   - Example: `at(X) & passage(Y) → +link(X, Y)`\n",
    "\n",
    "2. **Program Rules:**\n",
    "   - Define reasoning processes and determine:\n",
    "     - Which actions are appropriate (intentions).\n",
    "     - Which goals to pursue (desires).\n",
    "     - What is true or false (beliefs).\n",
    "\n",
    "3. **Action Rules:**\n",
    "   - Define the effects of actions (postconditions).\n",
    "\n",
    "---\n",
    "\n",
    "### **4-Step Reasoning Cycle**\n",
    "1. **Sense:**  \n",
    "   - Sensors detect stimuli, triggering percept rules to update the belief base.  \n",
    "\n",
    "2. **Think:**  \n",
    "   - Evaluate program rules to decide:  \n",
    "     - Goals (desires), facts (beliefs), and appropriate actions (intentions).\n",
    "\n",
    "3. **Decide:**  \n",
    "   - Prioritize actions (e.g., through planning) and select one to execute.\n",
    "\n",
    "4. **Act:**  \n",
    "   - Execute the action. If successful, update the belief base with its postconditions.\n",
    "\n",
    "---\n",
    "\n",
    "### **Goal-Oriented Agents: Full Cycle**\n",
    "- **Program Rules:** Logic for deciding actions.\n",
    "- **Environment:** World in which the agent operates.\n",
    "- **Percepts:** Data collected by sensors.\n",
    "- **Actuators:** Mechanisms to perform actions in the environment.\n",
    "- **Beliefs, Desires, Intentions:** Mental state used for reasoning.\n",
    "\n",
    "---\n",
    "\n",
    "### **Knowledge and Rules**\n",
    "- Represented as **logical statements** (usually predicate logic).\n",
    "- Supports:\n",
    "  - **Knowledge representation:** Facts stored as predicates.\n",
    "  - **Inference:** Deduction of new knowledge (similar to Prolog).\n",
    "\n",
    "- **Reserved Predicates:**\n",
    "  - Add/remove facts to/from the belief base (`assert`, `retract` in Prolog).\n",
    "  - Add/remove goals to/from the desire base.\n",
    "  - Add actions to the intention base.\n",
    "\n",
    "---\n",
    "\n",
    "### **Goal-Orientation vs. Planning**\n",
    "1. **Relationship:**\n",
    "   - Planning agents must be goal-oriented because plans are made to achieve goals.\n",
    "   - Not all goal-oriented agents explicitly plan.\n",
    "\n",
    "2. **Examples of Goal-Orientation without Planning:**\n",
    "   - **Dynamic programming:** Optimize actions based on a state-value function.\n",
    "   - **Evolutionary search:** Use genetic algorithms to achieve goals.\n",
    "   - **Reactive agents:** Respond directly to stimuli without constructing plans.\n",
    "   - **Reinforcement learning agents:** Learn actions to maximize rewards."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

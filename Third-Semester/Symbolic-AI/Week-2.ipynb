{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **State:** A specific situation or configuration of the problem. For example, in a puzzle, each arrangement of pieces is a state.\n",
    "- **State Space:** The set of all possible states that can exist in a problem. For instance, the state space for Tic Tac Toe includes all possible board configurations.\n",
    "- **Actions:** Actions represent possible moves or steps an agent can take to transition from one state to another (e.g., placing a queen in a chess game).\n",
    "- **Transition:** When an action is taken, it causes the state to change. For example, moving a queen from one position to another changes the chessboard state.\n",
    "- **Frontier:** the list of states that still can be expanded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Uninformed Search:\n",
    "Uninformed search algorithms don’t have prior knowledge of the problem domain. They explore blindly without any information on the cost or distance to the goal.\n",
    "\n",
    "#### Depth-first search:\n",
    "Memory efficient, time inefficient\n",
    "\n",
    "#### Breadth-first search:\n",
    "Optimal if each action has same cost\n",
    "\n",
    "Memory inefficient, time efficient\n",
    "\n",
    "<img src=\"https://static-assets.codecademy.com/Courses/CS102-Data-Structures-And-Algorithms/Breadth-First-Search-And-Depth-First-Search/Breadth-First-Tree-Traversal.gif\" alt=\"Breadth-First Search\" width=\"500\">\n",
    "\n",
    "#### *Iterative deepening:\n",
    "Complete, Optimal (if each action has same cost) and lower memory requirements\n",
    "\n",
    "Combines depth and breadth\n",
    "- For maxdepth (0 to …)\n",
    "- Push A to frontier.\n",
    "- { node=Pop frontier\n",
    "- If node.depth < maxdepth\n",
    "- Push node.children to frontier\n",
    "- } Repeat until frontier.empty or goal.\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*h3aYO43bClu-gkWlrURTMA.gif\" alt=\"ITS\" width=\"500\">\n",
    "\n",
    "- Start with Depth 0: The algorithm first searches the tree/graph up to depth 0 (only the start node).\n",
    "- Increase the Depth Limit: After finishing the search at depth 0, it increases the depth limit by 1 and explores all nodes up to depth 1.\n",
    "- Repeat: This process is repeated, incrementing the depth limit each time, until the goal is found or all nodes are explored.\n",
    "\n",
    "#### Uniform Cost Search:\n",
    "\n",
    "Memory efficient, time efficient\n",
    "\n",
    "- Push A to frontier; //add start node to frontier stack.\n",
    "- { node = pop argmin(c(n)); // remove lowest cost node from frontier\n",
    "- UpdateMinCostAndPush node.children to frontier; // add to top of stack\n",
    "- } Repeat until frontier.empty or node=goal; //fail or goal reached\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "## Informed (Heuristic h(n)) Search\n",
    "\n",
    "- **$f(n) = g(n) + h(n):$**\n",
    "    - g(n): The actual cost to reach the current node nn from the start.\n",
    "    - h(n): The estimated cost (heuristic) from node nn to the goal. The heuristic should be admissible (never overestimates the actual cost) or consistent (cost estimates decrease steadily).\n",
    "\n",
    "##### Example of h(n):\n",
    "If you’re navigating a map, g(n)g(n) would be the distance traveled so far, and h(n)h(n) could be the straight-line distance (Euclidean distance) to your destination. A* would guide you towards paths that seem both short and efficient based on those values.\n",
    "\n",
    "#### A* Search:\n",
    "\n",
    "Combines the actual cost to reach the node (g(n)) and the estimated cost from that node to the goal (h(n)). A* is both complete and optimal if the heuristic is admissible (never overestimates the cost) and consistent (monotonically non-increasing).\n",
    "\n",
    "- **A\\* Search** minimizes the total solution cost by using the function $ f(n) = g(n) + h(n) $.\n",
    "  - **Admissible:** Because Euclidean distance is the shortest possible path, it will never overestimate.\n",
    "  - **Consistent:** As you move closer to the goal, the estimated cost $ h(n) $ won’t increase unexpectedly.\n",
    "\n",
    "- **Algorithm Steps:**\n",
    "  1. Add the start node (A) to the frontier.\n",
    "  2. Repeatedly pick the node from the frontier with the lowest $ f(n) $ (best estimated total cost).\n",
    "  3. Add its child nodes to the frontier.\n",
    "  4. Continue until you reach the goal or the frontier is empty (failure).\n",
    "\n",
    "\n",
    "A* combines two main ideas: actual cost to reach a node and an estimated cost to the goal.\n",
    "\n",
    "<img src=\"https://d18l82el6cdm1i.cloudfront.net/uploads/hevQ7EbwVU-output_prgol9.gif\" alt=\"Breadth-First Search\" width=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Adversarial Search\n",
    "\n",
    "This is used in games where two players compete. The goal is to minimize the opponent's gains while maximizing your own.\n",
    "\n",
    "#### Minimax Algorithm:\n",
    "\n",
    "Simulates all possible moves for both players and chooses the action that maximizes your minimum gain (assuming the opponent plays optimally).\n",
    "\n",
    "Basically uninformed adversarial tree-search with leave nodes with a value (win/loss/draw) and other nodes have no or 0 value.\n",
    "\n",
    "<img src=\"../../Files/third-semester/sai/1.png\" alt=\"Minimax\" width=\"350\">\n",
    "\n",
    "```python\n",
    "def Minimax(node, turn):\n",
    "    if node.is_leaf():\n",
    "        return value(node)\n",
    "    \n",
    "    if turn:  # Maximizing player\n",
    "        for child in node.children:\n",
    "            u = max(u, Minimax(child, False))\n",
    "    else:  # Minimizing player\n",
    "        for child in node.children:\n",
    "            u = min(u, Minimax(child, True))\n",
    "    \n",
    "    return u\n",
    "```\n",
    "\n",
    "pruning as in A* and best-first search (when you know that a certain node is more promising than another) but now for adversarial setting.\n",
    "\n",
    "### Pruning in search:\n",
    "\n",
    "• Strictly: the process of removing or\n",
    "avoidance of suboptimal portions of the\n",
    "search tree, i.e. those portions that do not\n",
    "influence the final solution.\n",
    "\n",
    "\n",
    "• Not the same as a search heuristic, which\n",
    "prioritizes the frontier according to a\n",
    "predicted cost function.\n",
    "\n",
    "\n",
    "\n",
    "#### Alpha-Beta Pruning with Minimax:\n",
    "\n",
    "An optimization of Minimax that reduces the number of nodes evaluated by “pruning” branches that won’t affect the final decision.\n",
    "\n",
    "• Basically uninformed adversarial best-first search\n",
    "\n",
    "• Same assumptions as minimax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def alphabeta(node, isMaximizingPlayer, alpha, beta):\n",
    "    # If the node is a leaf node (i.e., end of the game)\n",
    "    if node.is_leaf():\n",
    "        return node.value()  # Return the value of the leaf node\n",
    "    \n",
    "    # If the current player is the maximizing player (the agent)\n",
    "    if isMaximizingPlayer:\n",
    "        maxEval = -infinity  # Initialize the maximum evaluation\n",
    "        for child in node.children:\n",
    "            # Recursively apply alphabeta on the child node\n",
    "            eval = alphabeta(child, False, alpha, beta)\n",
    "            maxEval = max(maxEval, eval)  # Update the best move for the maximizing player\n",
    "            alpha = max(alpha, eval)  # Update alpha\n",
    "            if beta <= alpha:  # Prune the search if beta is less than or equal to alpha\n",
    "                break\n",
    "        return maxEval\n",
    "    \n",
    "    # If the current player is the minimizing player (the opponent)\n",
    "    else:\n",
    "        minEval = infinity  # Initialize the minimum evaluation\n",
    "        for child in node.children:\n",
    "            # Recursively apply alphabeta on the child node\n",
    "            eval = alphabeta(child, True, alpha, beta)\n",
    "            minEval = min(minEval, eval)  # Update the best move for the minimizing player\n",
    "            beta = min(beta, eval)  # Update beta\n",
    "            if beta <= alpha:  # Prune the search if beta is less than or equal to alpha\n",
    "                break\n",
    "        return minEval\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

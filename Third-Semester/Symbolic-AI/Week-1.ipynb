{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding and consciousness: Human biological brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intelligent behavior does not imply the machine is conscious and understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, machines can be intelligent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Artificial General Intelligence :** reasoning, learning, problem solving, generalisation\n",
    "\n",
    "**Strong AI:** Machines that act intelligently can eventually also possess consciousness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Different approaches to AI:\n",
    "\n",
    "1. **Classic AI**: (Focus on model structure, formalism and architecture)\n",
    "    - Agent-based reasoning\n",
    "    - Utilizes search, logic, and rule-based systems\n",
    "    - Symbol manipulation\n",
    "    - Includes agents, environments, and memory\n",
    "\n",
    "2. **Machine Learning**\n",
    "\n",
    "3. **Cognitive Science/Cognitive Modelling**: (Focus on model structure, formalism and architecture)\n",
    "    - Replicating psychological and biological mechanisms that lead to intelligent behavior\n",
    "    - Utilizes frameworks like ACT-R and SOAR.\n",
    "\n",
    "4. **Computational Intelligence/Natural Computing:** (More Biological Approach, Focus on model outputs behavior and solution)\n",
    "    - Draws inspiration from biological systems for search and optimization\n",
    "    - Includes techniques like swarm intelligence* and genetic algorithms.\n",
    "\n",
    "*Swarm intelligence: agents interacting locally with one another and with the environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Classical (Symbolic) AI or Good Old-fashioned AI (GOFAI)\n",
    "\n",
    "focusses on knowledge representation and general purpose “reasoning” mechanisms.\n",
    "\n",
    "- Separation between knowledge and reasoning.\n",
    "- Generic reasoning (problem-solving) based on search and logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Rational agent** = an agent program that chooses actions such\n",
    "that for any given percept sequence the expectation of\n",
    "payoff for an action is maximal according to some pay-off\n",
    "function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "### Environment Properties\n",
    "\n",
    "##### Fully Observable – Partially Observable\n",
    "- Whether or not the state is perceived completely  \n",
    "- **Example:** Tic Tac Toe vs Stratego\n",
    "\n",
    "##### Single Agent – Multi Agent\n",
    "- Sometimes agents are competitive (adversarial), sometimes collaborative  \n",
    "- **Example:** Solitaire vs Tic Tac Toe\n",
    "\n",
    "##### Deterministic – Stochastic\n",
    "- If the next state is fully determined by the current state and action or not  \n",
    "- **Example:** Tetris vs Pacman\n",
    "\n",
    "##### Episodic – Sequential\n",
    "- In episodic tasks, the agent selects an action and the task is reset  \n",
    "- In sequential tasks, the agent repeatedly selects actions to progress  \n",
    "- **Example:** Duck Hunt vs Mario Bros\n",
    "\n",
    "##### Static – Dynamic\n",
    "- Dynamic environments can change while the agent is thinking (time passes by)  \n",
    "- Static environments only change when the agent does something to it (time does not pass by)  \n",
    "- **Example:** Pacman vs Solitaire\n",
    "\n",
    "##### Discrete – Continuous\n",
    "- Whether the states and actions are countable, i.e., when it makes sense to enumerate them  \n",
    "- **Example:** Tic Tac Toe vs Star Wars Battlefront\n",
    "\n",
    "##### Known Model – Learned Model\n",
    "- Not really an environment property, but more about what the agent knows about the environment  \n",
    "- Whether the effect (outcome) of actions on the environment is known or not  \n",
    "- **Example:** Driving lessons (you don’t yet know what effects your actions have on the car/road) vs Driver’s license (you know the effects of actions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "## Types of agents\n",
    "\n",
    "#### Reflexive agents\n",
    "• Picks actions based on current percept\n",
    "####  Model-based reflexive agents\n",
    "• Keeps track of the state of the world and uses that as well to pick actions.\n",
    "#### Goal-based agents\n",
    "• Has goal states, and plans/searches actions that satisfy paths to the goal\n",
    "states\n",
    "#### Utility-based agents\n",
    "• Use a utility function to decide the relative importance of outcomes and uses\n",
    "that as well to pick actions"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
